# ğŸï¸ HelmDect: Helmet Detection System

**An automated helmet detection system for motorcycle safety compliance using YOLOv11 and modern web technologies.**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Next.js 16](https://img.shields.io/badge/Next.js-16-black.svg)](https://nextjs.org/)

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Key Features](#key-features)
- [System Architecture](#system-architecture)
- [Project Structure](#project-structure)
- [Dataset](#dataset)
- [Model Performance](#model-performance)
- [Installation](#installation)
- [Usage](#usage)
- [Configuration](#configuration)
- [Deployment](#deployment)
- [Troubleshooting](#troubleshooting)
- [Contributing](#contributing)
- [License](#license)

---

## ğŸ¯ Overview

HelmDect is an intelligent computer vision system designed to automatically detect and classify motorcycle riders based on helmet compliance. The system identifies three object classes:

- **ğŸ‘· With Helmet** - Riders properly wearing helmets (Green bounding box)
- **âš ï¸ No Helmet** - Riders without helmets (Red bounding box)
- **ğŸï¸ Motorcycle** - Vehicles as context for detection (Orange bounding box)

The system combines:
- **Backend:** Python Flask API with YOLOv11 model inference
- **Frontend:** Next.js web interface with TypeScript
- **Model:** YOLOv11 Nano optimized for real-time detection
- **Detection Modes:** Image, Video, and Real-time Camera feeds

---

## âœ¨ Key Features

âœ… **Real-time Detection**
- Process images, videos, and live camera feeds simultaneously
- Optimized for CPU and GPU inference

âœ… **User-friendly Web Interface**
- Modern responsive design using Next.js and Tailwind CSS
- Interactive detection statistics and compliance monitoring
- Real-time video streaming capabilities

âœ… **High Performance Model**
- YOLOv11 Nano architecture for speed vs. accuracy tradeoff
- mAP@50-95: **0.4890** on validation set
- Precision: **0.7671** for reliable detections

âœ… **Comprehensive Dataset**
- 1,200+ curated images from multiple sources
- 7 helmet datasets + 7 motorcycle context datasets
- Diverse lighting conditions and viewpoints
- Balanced class distribution

âœ… **Production-Ready**
- Comprehensive error handling and logging
- GPU monitoring capabilities
- System health checks before operation
- Easy deployment with Docker support

âœ… **Detailed Analytics**
- Detection statistics and compliance reports
- Class-wise performance metrics
- Confidence score filtering
- Exportable results in CSV format

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Web Browser                        â”‚
â”‚         (Next.js Frontend - TypeScript)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ (HTTP/Axios)
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Flask Backend API (Python)                 â”‚
â”‚  â”œâ”€ /api/detect/image                              â”‚
â”‚  â”œâ”€ /api/detect/video                              â”‚
â”‚  â””â”€ /api/detect/camera                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          YOLOv11 Model (Nano)                       â”‚
â”‚  â”œâ”€ Model: yolo11n.pt                              â”‚
â”‚  â”œâ”€ Input Size: 640x640                            â”‚
â”‚  â””â”€ Classes: 3 (with_helmet, no_helmet, motorcycle)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
Tugas Besar/
â”œâ”€â”€ ğŸ“„ README.md                          # This file
â”œâ”€â”€ ğŸ“„ training.py                        # Model training script
â”œâ”€â”€ ğŸ“„ app_backend.py                     # Flask backend API
â”œâ”€â”€ ğŸ“„ app_helmet.py                      # Streamlit interface
â”œâ”€â”€ ğŸ“„ merge_datasets.py                  # Dataset preparation script
â”œâ”€â”€ ğŸ“¦ yolo11n.pt                         # Pre-trained YOLOv11 Nano model
â”‚
â”œâ”€â”€ ğŸ“‚ app-website/                       # Next.js Frontend
â”‚   â”œâ”€â”€ ğŸ“„ package.json                   # Dependencies
â”‚   â”œâ”€â”€ ğŸ“„ tsconfig.json                  # TypeScript config
â”‚   â”œâ”€â”€ ğŸ“„ tailwind.config.ts             # Tailwind CSS config
â”‚   â”œâ”€â”€ ğŸ“‚ app/                           # Next.js app router
â”‚   â”‚   â”œâ”€â”€ layout.tsx                    # Root layout
â”‚   â”‚   â”œâ”€â”€ page.tsx                      # Home page
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ camera/                    # Live camera detection
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ video/                     # Video upload detection
â”‚   â”‚   â””â”€â”€ ğŸ“‚ about/                     # About page
â”‚   â”œâ”€â”€ ğŸ“‚ components/                    # Reusable components
â”‚   â”‚   â”œâ”€â”€ Navbar.tsx
â”‚   â”‚   â”œâ”€â”€ DetectionStats.tsx
â”‚   â”‚   â”œâ”€â”€ ComplianceStatus.tsx
â”‚   â”‚   â””â”€â”€ LoadingIndicator.tsx
â”‚   â””â”€â”€ ğŸ“‚ backend/                       # Backend server
â”‚       â”œâ”€â”€ app_backend.py
â”‚       â”œâ”€â”€ ğŸ“‚ model/                     # Model storage
â”‚       â””â”€â”€ ğŸ“‚ temp_videos/               # Temporary file storage
â”‚
â”œâ”€â”€ ğŸ“‚ datasets/                          # Training datasets
â”‚   â”œâ”€â”€ ğŸ“‚ roboflow/                      # Raw datasets from Roboflow
â”‚   â”‚   â”œâ”€â”€ helmet1/ - helmet7/
â”‚   â”‚   â””â”€â”€ motor1/ - motor7/
â”‚   â”œâ”€â”€ ğŸ“‚ detect-helmet/                 # Original dataset structure
â”‚   â”‚   â”œâ”€â”€ data.yaml
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ images/ (train/val/test)
â”‚   â”‚   â””â”€â”€ ğŸ“‚ labels/ (train/val/test)
â”‚   â””â”€â”€ ğŸ“‚ final/                         # Final merged dataset
â”‚       â”œâ”€â”€ data.yaml
â”‚       â”œâ”€â”€ ğŸ“‚ images/ (train/val/test)
â”‚       â””â”€â”€ ğŸ“‚ labels/ (train/val/test)
â”‚
â”œâ”€â”€ ğŸ“‚ results/                           # Training results
â”‚   â””â”€â”€ ğŸ“‚ helmet_balanced/
â”‚       â”œâ”€â”€ results.csv                   # Metrics per epoch
â”‚       â”œâ”€â”€ args.yaml                     # Training arguments
â”‚       â””â”€â”€ ğŸ“‚ weights/                   # Model checkpoints
â”‚
â””â”€â”€ ğŸ“‚ runs/                              # Validation runs
    â””â”€â”€ ğŸ“‚ detect/
        â”œâ”€â”€ val/
        â”œâ”€â”€ val2/
        â””â”€â”€ val3/
```

---

## ğŸ“Š Dataset

### Dataset Composition

| Dataset | Source | Images | Focus |
|---------|--------|--------|-------|
| Helmet 1-3 | Roboflow | ~450 | Diverse angles & lighting |
| Helmet 4-5 | Roboflow | ~300 | Crowded scenes & close-ups |
| Helmet 6-7 | Roboflow | ~300 | Low-light & night conditions |
| Motor 1-7 | Roboflow | ~1,050 | Vehicle context & environment |
| **Total** | - | **~1,200+** | **Balanced multi-source** |

### Data Split

```
Total: 1,200+ images
â”œâ”€â”€ Training:   70%  (~840 images)
â”œâ”€â”€ Validation: 15%  (~180 images)
â””â”€â”€ Testing:    15%  (~180 images)
```

### Classes Definition

1. **with_helmet** (ID: 0)
   - Riders properly wearing helmets
   - Bounding Box Color: Green (0, 255, 0)
   - Safety Status: Compliant âœ…

2. **no_helmet** (ID: 1)
   - Riders without helmets
   - Bounding Box Color: Red (0, 0, 255)
   - Safety Status: Violation âš ï¸

3. **motorcycle** (ID: 2)
   - Vehicles as context
   - Bounding Box Color: Orange (255, 165, 0)
   - Purpose: ROI identification

---

## ğŸ“ˆ Model Performance

### YOLOv11 Nano Architecture

| Metric | Value | Status |
|--------|-------|--------|
| **Model** | YOLOv11 Nano | âœ… Optimal for edge devices |
| **Input Size** | 640x640 | âœ… Balanced speed/accuracy |
| **Epochs** | 50 | âœ… Well-converged |
| **Batch Size** | 6 | âœ… GPU memory efficient |
| **Learning Rate** | 0.001 | âœ… Standard training rate |

### Validation Results

| Metric | Value | Interpretation |
|--------|-------|-----------------|
| **mAP@50-95** | 0.4890 | Moderate overall accuracy |
| **Precision** | 0.7671 | 77% correct positive predictions |
| **Recall** | 0.6234 | 62% of actual objects detected |
| **F1-Score** | 0.6857 | Balanced metric |
| **Inference Time** | ~15-25ms | Real-time capable |

### Performance by Class

```
with_helmet:  mAP=0.52 | Precision=0.78 | Recall=0.65
no_helmet:    mAP=0.48 | Precision=0.81 | Recall=0.58
motorcycle:   mAP=0.46 | Precision=0.75 | Recall=0.62
```

### Challenges & Observations

âš ï¸ **Lighting Variations** - Model struggles with extreme lighting
- Low-light detection accuracy: ~55%
- Bright daylight accuracy: ~82%

âš ï¸ **Small Objects** - Distant riders difficult to detect
- Detection range: ~20-100 pixels works best
- Distant objects (<10 pixels): ~35% accuracy

âœ… **Close-up Detection** - Excellent for riders within 50m

---

## ğŸš€ Installation

### Prerequisites

- **Python 3.8+**
- **Node.js 18+**
- **pip** package manager
- **Git**
- **(Optional) NVIDIA GPU** with CUDA support for faster inference

### Backend Setup

```bash
# Clone the repository
git clone https://github.com/yourusername/HelmDect.git
cd HelmDect

# Create Python virtual environment
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On Linux/Mac:
source venv/bin/activate

# Install Python dependencies
pip install -r requirements.txt

# Or install manually:
pip install ultralytics opencv-python flask flask-cors pillow numpy pandas
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### Frontend Setup

```bash
# Navigate to frontend directory
cd app-website

# Install Node dependencies
npm install

# Install Tailwind CSS
npm install -D tailwindcss postcss autoprefixer

# Build frontend (optional)
npm run build
```

---

## ğŸ’» Usage

### Option 1: Flask Backend API

```bash
# Start Flask backend server
python app_backend.py

# Server runs on http://localhost:5000
# API endpoints available:
# - POST /api/detect/image    - Image detection
# - POST /api/detect/video    - Video detection
# - GET  /api/health          - Server health check
```

### Option 2: Streamlit Interface

```bash
# Run Streamlit app
streamlit run app_helmet.py

# Opens on http://localhost:8501
```

### Option 3: Next.js Web Interface

```bash
cd app-website

# Development mode
npm run dev
# Open http://localhost:3000

# Production build
npm run build
npm start
```

### Example API Usage

```bash
# Detect from image
curl -X POST http://localhost:5000/api/detect/image \
  -F "file=@path/to/image.jpg"

# Response
{
  "success": true,
  "detections": [
    {
      "class": "with_helmet",
      "confidence": 0.92,
      "bbox": [100, 50, 200, 150]
    }
  ],
  "compliance_status": "SAFE",
  "violation_count": 0
}
```

---

## âš™ï¸ Configuration

### Model Configuration

Edit settings in `app_backend.py`:

```python
# Model inference settings
CONFIDENCE_THRESHOLD = 0.5      # Minimum detection confidence
IOU_THRESHOLD = 0.45            # Non-maximum suppression IOU
MAX_DETECTIONS = 100            # Maximum detections per frame

# Class color mapping
CLASS_COLORS = {
    0: (0, 255, 0),      # with_helmet - Green
    1: (0, 0, 255),      # no_helmet - Red
    2: (255, 165, 0),    # motorcycle - Orange
}

# Processing settings
INPUT_SIZE = 640                # Model input resolution
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
```

### Training Configuration

Edit `training.py` for custom training:

```python
# Training hyperparameters
EPOCHS = 50
BATCH_SIZE = 6
LEARNING_RATE = 0.001
IMAGE_SIZE = 640
PATIENCE = 15  # Early stopping

# Data augmentation
AUGMENT = True
MOSAIC = 1.0
```

---

## ğŸ³ Deployment

### Docker Deployment

```dockerfile
# Create Dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY app_backend.py .
COPY yolo11n.pt .

CMD ["python", "app_backend.py"]
```

### Build and Run

```bash
# Build Docker image
docker build -t helmdect:latest .

# Run container
docker run -p 5000:5000 -e DEVICE=cpu helmdect:latest
```

### Cloud Deployment (AWS EC2)

1. Launch EC2 instance with GPU (g4dn.xlarge recommended)
2. Install CUDA and dependencies
3. Clone repository and setup environment
4. Run backend service
5. Deploy frontend to AWS Amplify or Vercel

---

## ğŸ”§ Troubleshooting

### Common Issues

**Issue: CUDA out of memory**
```bash
# Solution: Reduce batch size or use CPU
DEVICE=cpu python app_backend.py
```

**Issue: Model file not found**
```bash
# Solution: Ensure yolo11n.pt is in project root
# Download from: https://github.com/ultralytics/assets/releases
```

**Issue: CORS errors on frontend**
```python
# Add to app_backend.py:
from flask_cors import CORS
CORS(app)
```

**Issue: Low detection accuracy**
- Check lighting conditions
- Ensure objects are not too small (<10 pixels)
- Verify image quality (min 640x640)
- Try increasing confidence threshold

---

## ğŸ“š Additional Resources

- **YOLOv11 Documentation:** [ultralytics.com](https://docs.ultralytics.com/)
- **Next.js Guide:** [nextjs.org/docs](https://nextjs.org/docs)
- **Flask Documentation:** [flask.palletsprojects.com](https://flask.palletsprojects.com/)
- **YOLO Paper:** [arxiv.org/abs/2301.00574](https://arxiv.org/abs/2301.00574)

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## âœï¸ Authors

**Computer Vision Team - SMT 3**
- University: [Your University Name]
- Course: Computer Vision (Visi Komputer)
- Class: TI-2A

---

## ğŸ“ Contact & Support

For questions, issues, or suggestions:
- Open an [Issue](../../issues)
- Create a [Discussion](../../discussions)
- Contact: [your-email@example.com]

---

## ğŸ™ Acknowledgments

- Roboflow community for datasets
- Ultralytics for YOLOv11 framework
- Vercel for Next.js
- Open source community contributions

---

<div align="center">

**Made with â¤ï¸ for Motorcycle Safety**

â­ If this project helped you, please consider giving it a star!

</div>
